{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1GztekP-YE7fw981ouZ4jsHnWdHS8IL1u","timestamp":1682311632110}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os \n","import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"V3LU-1lPPBnv","executionInfo":{"status":"ok","timestamp":1682313014500,"user_tz":-540,"elapsed":6,"user":{"displayName":"정우철","userId":"12871903895018674056"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"uAWEUX9TPBGl","executionInfo":{"status":"ok","timestamp":1682313021343,"user_tz":-540,"elapsed":6847,"user":{"displayName":"정우철","userId":"12871903895018674056"}},"outputId":"0efcc57d-e503-4906-85d4-35753179ac68"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.12.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["import tensorflow as tf\n","tf.__version__"]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import SimpleRNN, GRU, LSTM, Dense, Bidirectional"],"metadata":{"id":"EUxPPVtB3KdJ","executionInfo":{"status":"ok","timestamp":1682313021344,"user_tz":-540,"elapsed":6,"user":{"displayName":"정우철","userId":"12871903895018674056"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# 2. Keras로 LSTM 구현하기"],"metadata":{"id":"wZ3XZUuSUNLC"}},{"cell_type":"markdown","source":["- 기본적인 활용은 simple RNN과 거의 동일"],"metadata":{"id":"nunBUxO_pod0"}},{"cell_type":"markdown","source":["https://keras.io/api/layers/recurrent_layers/lstm/"],"metadata":{"id":"fu6On_amU2jt"}},{"cell_type":"code","source":["x = tf.random.uniform((1, 3, 4))\n","x.shape # (데이터 개수, seq의 길이(단어의 개수), 단어의 임베딩 차원)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IVTL2nRQq3IU","executionInfo":{"status":"ok","timestamp":1682313143489,"user_tz":-540,"elapsed":4,"user":{"displayName":"정우철","userId":"12871903895018674056"}},"outputId":"a71495c8-2990-4a84-8b8a-761544a72e32"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([1, 3, 4])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["LSTM(8)(x) # unit 수 - hidden state의 차원의 크기 --> 누적된 seq의 정보가 8차원 vector에 기록\n","           # 따라서, 정보가 많으면 unit의 수가 더 커야함"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tm0MTr23rZKT","executionInfo":{"status":"ok","timestamp":1682313294528,"user_tz":-540,"elapsed":783,"user":{"displayName":"정우철","userId":"12871903895018674056"}},"outputId":"f415aae9-76d1-49f5-9f2b-8e19f40040e1"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n","array([[ 0.05510229, -0.15806057, -0.0120617 ,  0.21166593, -0.00374101,\n","         0.13033758, -0.04504932,  0.12556145]], dtype=float32)>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["out =  LSTM(8, return_sequences = True, return_state = True)(x)\n","out # 모든 seq의 hidden state / 마지막 hidden state / cell state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-qixoJcr72J","executionInfo":{"status":"ok","timestamp":1682313368904,"user_tz":-540,"elapsed":3,"user":{"displayName":"정우철","userId":"12871903895018674056"}},"outputId":"1095bfce-20fa-4fdc-9dd7-7630a8d7dfe6"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Tensor: shape=(1, 3, 8), dtype=float32, numpy=\n"," array([[[-0.1027828 , -0.02570496,  0.04342749,  0.1212106 ,\n","          -0.05779904, -0.07455692, -0.02374983,  0.11319604],\n","         [-0.09873844, -0.00498222,  0.07658664,  0.18294671,\n","          -0.08071811, -0.08066523, -0.03855846,  0.1389728 ],\n","         [-0.11606564, -0.01325427,  0.12444531,  0.2882171 ,\n","          -0.10411558, -0.08987059, -0.0307428 ,  0.19376348]]],\n","       dtype=float32)>,\n"," <tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n"," array([[-0.11606564, -0.01325427,  0.12444531,  0.2882171 , -0.10411558,\n","         -0.08987059, -0.0307428 ,  0.19376348]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n"," array([[-0.25342947, -0.02778663,  0.25038716,  0.61581564, -0.18369953,\n","         -0.20878783, -0.06350601,  0.37216583]], dtype=float32)>]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["len(out)\n","# RNN과 다르게 len이 3인 이유는 LSTM은 RNN과의 차이점 존재 --> cell state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xgO7PygZsOxI","executionInfo":{"status":"ok","timestamp":1682313379765,"user_tz":-540,"elapsed":294,"user":{"displayName":"정우철","userId":"12871903895018674056"}},"outputId":"95950388-badc-4b61-d3be-2a2125da0e53"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["- 양방향 RNN"],"metadata":{"id":"pgDycWyntzwW"}},{"cell_type":"code","source":["Bidirectional(LSTM(8))(x) # 마지막 hidden state가 두 배가 됨"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g396ZkymtnUI","executionInfo":{"status":"ok","timestamp":1682313761353,"user_tz":-540,"elapsed":271,"user":{"displayName":"정우철","userId":"12871903895018674056"}},"outputId":"8f144021-ce2f-4061-8b1f-397c9b0e997c"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n","array([[ 0.09339321, -0.16120915, -0.1861935 ,  0.03517503, -0.10660518,\n","        -0.08419734,  0.04895993, -0.17647159,  0.00752816,  0.20217797,\n","        -0.02757097, -0.01164663, -0.01385706,  0.2689354 , -0.00155638,\n","         0.040525  ]], dtype=float32)>"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["사실 실제로 SimpleRNN이 사용되는 경우는 거의 없습니다. 이보다는 LSTM이나 GRU을 주로 사용하는데, 이번에는 임의의 입력에 대해서 LSTM을 사용할 경우를 보겠습니다."],"metadata":{"id":"Y8jXe-GJTsFo"}},{"cell_type":"markdown","source":["- 품사 태깅 문제"],"metadata":{"id":"V2n9MW0auSAG"}},{"cell_type":"code","source":["John = [1,0,0,0]\n","loves = [0,1,0,0]\n","Jane = [0,0,1,0]\n","Alex = [0,0,0,1]\n","\n","train_X = np.array([\n","    [ John, loves, Jane ],\n","    [ Jane, loves, Alex ]\n","]).astype(np.float32)\n","\n","S = [0] # subject\n","V = [1] # verb\n","O = [2] # object\n","\n","idx2tag = ['S', 'V', 'O']\n","\n","train_Y = np.array([[S, V, O], [S, V, O]]).astype(np.float32)\n","\n","print(\"train_y\", train_Y)\n","print(\"train_X의 shape\", train_X.shape)\n","print(\"train_Y의 shape\", train_Y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SFTk_0UQ4DEj","executionInfo":{"status":"ok","timestamp":1682314136609,"user_tz":-540,"elapsed":622,"user":{"displayName":"정우철","userId":"12871903895018674056"}},"outputId":"b306a995-da26-42e2-93ca-a28633ea1dfa"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["train_y [[[0.]\n","  [1.]\n","  [2.]]\n","\n"," [[0.]\n","  [1.]\n","  [2.]]]\n","train_X의 shape (2, 3, 4)\n","train_Y의 shape (2, 3, 1)\n"]}]},{"cell_type":"code","source":["num_classes = 3\n","input_dim = 4  \n","sequence_length = 3\n","learning_rate = 0.1\n","\n","\n","lstm = LSTM(num_classes)\n","output = lstm(train_X)\n","\n","print('hidden state : {}, shape: {}'.format(output, output.shape))"],"metadata":{"id":"DIW2YsQnUTpo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# return_sequences = True \n","\n","lstm = LSTM(3, return_sequences=True, return_state=True)\n","whole_seq_output, final_memory_state, final_carry_state = lstm(train_X)\n","\n","print('whole_seq_output: {}, shape: {}'.format(whole_seq_output, whole_seq_output.shape))\n","print('final_memory_state : {}, shape: {}'.format(final_memory_state, final_memory_state.shape))\n","print('final_carry_state : {}, shape: {}'.format(final_carry_state, final_carry_state.shape))"],"metadata":{"id":"eMRrjZxNUWpc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- LSTM"],"metadata":{"id":"zrd2Xvsqy1rR"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"wrDoWxneVeFG","executionInfo":{"status":"ok","timestamp":1682314567525,"user_tz":-540,"elapsed":377,"user":{"displayName":"정우철","userId":"12871903895018674056"}}},"outputs":[],"source":["from tensorflow.keras import layers, models\n","\n","lstm_model = models.Sequential() #모델 호출\n","lstm_model.add(\n","    layers.LSTM(units=3,\n","                input_shape = (3,4), \n","                return_sequences = True, # !!!\n","                name='LSTM-1')\n","    )\n","\n","lstm_model.add(\n","    layers.Dense(\n","        units=3,\n","        input_shape=(3,3), \n","        activation= 'softmax', \n","        name='hidden-to-output')) # 출력을 위한 FFN\n","\n","\n","lstm_model.compile(\n","    loss='sparse_categorical_crossentropy', # 분류? 회귀? 생성? 추천? --> target 형태\n","    optimizer='adam',\n","    metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"status":"ok","timestamp":1682314574340,"user_tz":-540,"elapsed":4781,"user":{"displayName":"정우철","userId":"12871903895018674056"}},"id":"Q02WgSBMVeFS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"be7ea3d1-c1df-4093-e8ce-e6f35699a0fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 [==============================] - 3s 3s/step - loss: 1.0739 - accuracy: 0.3333\n","Epoch 2/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0734 - accuracy: 0.3333\n","Epoch 3/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0729 - accuracy: 0.3333\n","Epoch 4/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0724 - accuracy: 0.3333\n","Epoch 5/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0719 - accuracy: 0.3333\n","Epoch 6/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0715 - accuracy: 0.5000\n","Epoch 7/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0710 - accuracy: 0.5000\n","Epoch 8/100\n","1/1 [==============================] - 0s 16ms/step - loss: 1.0705 - accuracy: 0.5000\n","Epoch 9/100\n","1/1 [==============================] - 0s 16ms/step - loss: 1.0700 - accuracy: 0.5000\n","Epoch 10/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0695 - accuracy: 0.5000\n","Epoch 11/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0690 - accuracy: 0.5000\n","Epoch 12/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0685 - accuracy: 0.5000\n","Epoch 13/100\n","1/1 [==============================] - 0s 10ms/step - loss: 1.0680 - accuracy: 0.5000\n","Epoch 14/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0675 - accuracy: 0.5000\n","Epoch 15/100\n","1/1 [==============================] - 0s 10ms/step - loss: 1.0670 - accuracy: 0.5000\n","Epoch 16/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0665 - accuracy: 0.5000\n","Epoch 17/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0660 - accuracy: 0.5000\n","Epoch 18/100\n","1/1 [==============================] - 0s 21ms/step - loss: 1.0655 - accuracy: 0.5000\n","Epoch 19/100\n","1/1 [==============================] - 0s 22ms/step - loss: 1.0650 - accuracy: 0.6667\n","Epoch 20/100\n","1/1 [==============================] - 0s 15ms/step - loss: 1.0645 - accuracy: 0.6667\n","Epoch 21/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0640 - accuracy: 0.6667\n","Epoch 22/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0635 - accuracy: 0.6667\n","Epoch 23/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0630 - accuracy: 0.6667\n","Epoch 24/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0625 - accuracy: 0.6667\n","Epoch 25/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0620 - accuracy: 0.6667\n","Epoch 26/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0615 - accuracy: 0.6667\n","Epoch 27/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0610 - accuracy: 0.6667\n","Epoch 28/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0605 - accuracy: 0.6667\n","Epoch 29/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0600 - accuracy: 0.6667\n","Epoch 30/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0595 - accuracy: 0.6667\n","Epoch 31/100\n","1/1 [==============================] - 0s 15ms/step - loss: 1.0589 - accuracy: 0.6667\n","Epoch 32/100\n","1/1 [==============================] - 0s 17ms/step - loss: 1.0584 - accuracy: 0.6667\n","Epoch 33/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0579 - accuracy: 0.6667\n","Epoch 34/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0574 - accuracy: 0.6667\n","Epoch 35/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0569 - accuracy: 0.6667\n","Epoch 36/100\n","1/1 [==============================] - 0s 15ms/step - loss: 1.0564 - accuracy: 0.6667\n","Epoch 37/100\n","1/1 [==============================] - 0s 16ms/step - loss: 1.0558 - accuracy: 0.6667\n","Epoch 38/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0553 - accuracy: 0.6667\n","Epoch 39/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0548 - accuracy: 0.6667\n","Epoch 40/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0543 - accuracy: 0.6667\n","Epoch 41/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0537 - accuracy: 0.6667\n","Epoch 42/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0532 - accuracy: 0.6667\n","Epoch 43/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0527 - accuracy: 0.6667\n","Epoch 44/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0521 - accuracy: 0.6667\n","Epoch 45/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0516 - accuracy: 0.6667\n","Epoch 46/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0510 - accuracy: 0.6667\n","Epoch 47/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0505 - accuracy: 0.6667\n","Epoch 48/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0499 - accuracy: 0.6667\n","Epoch 49/100\n","1/1 [==============================] - 0s 16ms/step - loss: 1.0494 - accuracy: 0.6667\n","Epoch 50/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0488 - accuracy: 0.6667\n","Epoch 51/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0483 - accuracy: 0.6667\n","Epoch 52/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0477 - accuracy: 0.6667\n","Epoch 53/100\n","1/1 [==============================] - 0s 16ms/step - loss: 1.0472 - accuracy: 0.6667\n","Epoch 54/100\n","1/1 [==============================] - 0s 16ms/step - loss: 1.0466 - accuracy: 0.6667\n","Epoch 55/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0460 - accuracy: 0.6667\n","Epoch 56/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0455 - accuracy: 0.6667\n","Epoch 57/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0449 - accuracy: 0.6667\n","Epoch 58/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0443 - accuracy: 0.6667\n","Epoch 59/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0437 - accuracy: 0.6667\n","Epoch 60/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0432 - accuracy: 0.6667\n","Epoch 61/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0426 - accuracy: 0.6667\n","Epoch 62/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0420 - accuracy: 0.6667\n","Epoch 63/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0414 - accuracy: 0.6667\n","Epoch 64/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0408 - accuracy: 0.6667\n","Epoch 65/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0402 - accuracy: 0.6667\n","Epoch 66/100\n","1/1 [==============================] - 0s 15ms/step - loss: 1.0396 - accuracy: 0.6667\n","Epoch 67/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0390 - accuracy: 0.6667\n","Epoch 68/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0383 - accuracy: 0.6667\n","Epoch 69/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0377 - accuracy: 0.6667\n","Epoch 70/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0371 - accuracy: 0.6667\n","Epoch 71/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0365 - accuracy: 0.6667\n","Epoch 72/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0359 - accuracy: 0.6667\n","Epoch 73/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0352 - accuracy: 0.6667\n","Epoch 74/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0346 - accuracy: 0.6667\n","Epoch 75/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0339 - accuracy: 0.6667\n","Epoch 76/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0333 - accuracy: 0.6667\n","Epoch 77/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0326 - accuracy: 0.6667\n","Epoch 78/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0320 - accuracy: 0.6667\n","Epoch 79/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0313 - accuracy: 0.6667\n","Epoch 80/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0306 - accuracy: 0.6667\n","Epoch 81/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0300 - accuracy: 0.6667\n","Epoch 82/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0293 - accuracy: 0.6667\n","Epoch 83/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0286 - accuracy: 0.6667\n","Epoch 84/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0279 - accuracy: 0.6667\n","Epoch 85/100\n","1/1 [==============================] - 0s 15ms/step - loss: 1.0272 - accuracy: 0.6667\n","Epoch 86/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0265 - accuracy: 0.8333\n","Epoch 87/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0258 - accuracy: 0.8333\n","Epoch 88/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0251 - accuracy: 0.8333\n","Epoch 89/100\n","1/1 [==============================] - 0s 17ms/step - loss: 1.0244 - accuracy: 0.8333\n","Epoch 90/100\n","1/1 [==============================] - 0s 19ms/step - loss: 1.0237 - accuracy: 0.8333\n","Epoch 91/100\n","1/1 [==============================] - 0s 15ms/step - loss: 1.0230 - accuracy: 0.8333\n","Epoch 92/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0222 - accuracy: 0.8333\n","Epoch 93/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0215 - accuracy: 0.8333\n","Epoch 94/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0208 - accuracy: 0.8333\n","Epoch 95/100\n","1/1 [==============================] - 0s 15ms/step - loss: 1.0200 - accuracy: 0.8333\n","Epoch 96/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0192 - accuracy: 0.8333\n","Epoch 97/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0185 - accuracy: 0.8333\n","Epoch 98/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0177 - accuracy: 0.8333\n","Epoch 99/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0169 - accuracy: 0.8333\n","Epoch 100/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0162 - accuracy: 0.8333\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f04c8fa5880>"]},"metadata":{},"execution_count":16}],"source":["lstm_model.fit(train_X, train_Y, epochs= 100)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"status":"ok","timestamp":1682314696348,"user_tz":-540,"elapsed":1460,"user":{"displayName":"정우철","userId":"12871903895018674056"}},"id":"erlcuC6yVu3b","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8e7c4608-3dfb-4429-e5b3-7b905550bdf2"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 980ms/step\n","[[0.3516856  0.30227014 0.34604418]\n"," [0.32119507 0.38397402 0.29483098]\n"," [0.3234248  0.3205833  0.3559919 ]]\n","[0 1 2]\n","\tPrediction str:  SVO\n","[[0.34340426 0.30303183 0.35356385]\n"," [0.31654036 0.38435557 0.29910412]\n"," [0.3287321  0.3150349  0.356233  ]]\n","[2 1 2]\n","\tPrediction str:  OVO\n"]}],"source":["predictions = lstm_model.predict(train_X) # 3개의 class에 대한 확률값\n","for i, prediction in enumerate(predictions):\n","  print(prediction)\n","  print(np.argmax(prediction, axis=1)) # 확률이 큰 index --> class\n","  result_str = [idx2tag[c] for c in np.argmax(prediction, axis=1) ] # index에서 tag 확인\n","  print(\"\\tPrediction str: \", \"\".join(result_str))"]},{"cell_type":"markdown","metadata":{"id":"JgargDsAVu3i"},"source":["모델을 이해하려면 weight 개수(W0\\~Wn)를 세어봐야 합니다."]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"status":"ok","timestamp":1682314839891,"user_tz":-540,"elapsed":379,"user":{"displayName":"정우철","userId":"12871903895018674056"}},"id":"oPqHUNICVu3j","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f05adcba-67ae-44ca-d6b7-265e442b28a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," LSTM-1 (LSTM)               (None, 3, 3)              96        \n","                                                                 \n"," hidden-to-output (Dense)    (None, 3, 3)              12        \n","                                                                 \n","=================================================================\n","Total params: 108\n","Trainable params: 108\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["lstm_model.summary() # RNN에 비해 LSTM이 4배 수준의 parameter 수를 보인다 --> 모델의 복잡도 증가(더 복잡한 문제 해결한다는 '장점' but! 더 많은 데이터를 필요로 한다는 '단점')"]},{"cell_type":"code","source":["for model_weight in lstm_model.weights:\n","    print(model_weight.name, '=>', model_weight.shape)"],"metadata":{"id":"UeeSNZ4oV1z7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682314846190,"user_tz":-540,"elapsed":264,"user":{"displayName":"정우철","userId":"12871903895018674056"}},"outputId":"1d1dc9e5-8cca-4185-a17e-a46ced619092"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["LSTM-1/lstm_cell_6/kernel:0 => (4, 12)\n","LSTM-1/lstm_cell_6/recurrent_kernel:0 => (3, 12)\n","LSTM-1/lstm_cell_6/bias:0 => (12,)\n","hidden-to-output/kernel:0 => (3, 3)\n","hidden-to-output/bias:0 => (3,)\n"]}]},{"cell_type":"markdown","source":["### 문제1 "],"metadata":{"id":"s4yvLeLx4abv"}},{"cell_type":"code","source":["model = Sequential()\n","model.add(LSTM(7, input_shape=(100,5)))\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8BATfHNX4aR0","executionInfo":{"status":"ok","timestamp":1662133619202,"user_tz":-540,"elapsed":463,"user":{"displayName":"이소연","userId":"16388319312927188329"}},"outputId":"a1a13406-38f5-4618-a6e8-1564d1990757"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_3 (LSTM)               (None, 7)                 364       \n","                                                                 \n","=================================================================\n","Total params: 364\n","Trainable params: 364\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["- W_forget : (num_units + input_dim + 1) * num_units\n","- W_input : (num_units + input_dim + 1) * num_units\n","- W_output : (num_units + input_dim + 1) * num_units\n","- W_cell : (num_units + input_dim + 1) * num_units"],"metadata":{"id":"unV7265X-ZhO"}},{"cell_type":"markdown","source":["### 문제2"],"metadata":{"id":"fUApe9np4ktO"}},{"cell_type":"code","source":["model = Sequential()\n","model.add(LSTM(5, input_shape = (2, 10)))\n","model.add(Dense(1))\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cqHdlwGy4kll","executionInfo":{"status":"ok","timestamp":1662133798776,"user_tz":-540,"elapsed":7,"user":{"displayName":"이소연","userId":"16388319312927188329"}},"outputId":"12152ad2-7a3e-4e6f-8344-977526141131"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_4 (LSTM)               (None, 5)                 320       \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 6         \n","                                                                 \n","=================================================================\n","Total params: 326\n","Trainable params: 326\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["- W_forget : (num_units + input_dim + 1) * num_units\n","- W_input : (num_units + input_dim + 1) * num_units\n","- W_output : (num_units + input_dim + 1) * num_units\n","- W_cell : (num_units + input_dim + 1) * num_units"],"metadata":{"id":"wgOMIFYm-da-"}},{"cell_type":"code","source":["# weight 개수 카운팅"],"metadata":{"id":"X9ioBYCi-efB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 문제3"],"metadata":{"id":"piOmwqSq4aNK"}},{"cell_type":"code","source":["model = Sequential()\n","model.add(LSTM(5, input_shape = (2, 10), return_sequences=True))\n","model.add(LSTM(7))\n","model.add(Dense(1))\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mMFgSK9I4aHT","executionInfo":{"status":"ok","timestamp":1662133834835,"user_tz":-540,"elapsed":531,"user":{"displayName":"이소연","userId":"16388319312927188329"}},"outputId":"5e46d30e-2e3f-475b-a877-5265289580b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_5 (LSTM)               (None, 2, 5)              320       \n","                                                                 \n"," lstm_6 (LSTM)               (None, 7)                 364       \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 8         \n","                                                                 \n","=================================================================\n","Total params: 692\n","Trainable params: 692\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# 첫번째 레이어의 파라미터 개수"],"metadata":{"id":"3vqoSLcBV2OK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 두번째 레이어의 파라미터 개수 \n"],"metadata":{"id":"8wH6uSKU5aac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 세번째 레이어의 파라미터 개수 "],"metadata":{"id":"GshfgJTC5j3f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Keras로 GRU 구현하기"],"metadata":{"id":"SDyNG1swysm0"}},{"cell_type":"markdown","source":["https://keras.io/api/layers/recurrent_layers/gru/"],"metadata":{"id":"VcdVCSuwysnC"}},{"cell_type":"code","source":["gru = GRU(num_classes)\n","output = gru(train_X)\n","\n","print('hidden state : {}, shape: {}'.format(output, output.shape))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1662133897203,"user_tz":-540,"elapsed":376,"user":{"displayName":"이소연","userId":"16388319312927188329"}},"id":"6Nwqw_wyysnC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c1db6a26-24e9-4381-fa0f-e38929506b8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hidden state : [[-0.3331254   0.15914953 -0.20464015]\n"," [-0.226817    0.35800463 -0.16532332]], shape: (2, 3)\n"]}]},{"cell_type":"code","source":["# return_sequences = True \n","gru = GRU(3, return_sequences=True, return_state=True)\n","whole_sequence_output, final_state= gru(train_X)\n","\n","print('whole_seq_output: {}, shape: {}'.format(whole_seq_output, whole_seq_output.shape))\n","print('final_state : {}, shape: {}'.format(final_state, final_state.shape))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1662133897576,"user_tz":-540,"elapsed":2,"user":{"displayName":"이소연","userId":"16388319312927188329"}},"id":"vUYfG_J3ysnC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8ca8776d-40ec-41bd-f7c3-3623e98c857e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["whole_seq_output: [[[-0.09133016 -0.02071412  0.14170164]\n","  [ 0.02361282  0.06159054  0.03471249]\n","  [ 0.06012786 -0.04471743 -0.08892121]]\n","\n"," [[ 0.03587217 -0.0941782  -0.11587585]\n","  [ 0.08149255  0.02020295 -0.18497597]\n","  [ 0.03355836 -0.02213107 -0.14921774]]], shape: (2, 3, 3)\n","final_state : [[ 0.10870809  0.3283546  -0.2419539 ]\n"," [-0.13706805 -0.10124536 -0.31973392]], shape: (2, 3)\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import layers, models\n","\n","gru_model = models.Sequential() #모델 호출\n","gru_model.add(\n","    layers.GRU(units=3,\n","                input_shape = (3,4), \n","                return_sequences = True, # !!!\n","                reset_after = False,\n","                name='GRU')\n","    )\n","# reset_after : keras 구현을 하면서 병렬처리를 위해 공식을 수정(bias를 2개로 나눔)하였는데, 원래 논문에 나온 공식으로 계산하기 위해 False로 수정\n","\n","gru_model.add(\n","    layers.Dense(\n","        units=3,\n","        input_shape=(3,3), \n","        activation= 'softmax', \n","        name='hidden-to-output')) # 출력을 위한 FFN\n","\n","\n","gru_model.compile(\n","    loss='sparse_categorical_crossentropy', # 분류? 회귀? 생성? 추천? --> target 형태\n","    optimizer='adam',\n","    metrics=['accuracy'])\n"],"metadata":{"id":"mnadMZn92COh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1662133900841,"user_tz":-540,"elapsed":2857,"user":{"displayName":"이소연","userId":"16388319312927188329"}},"id":"cG-hBKJWysnD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2c82c78-b389-49b9-a619-c1de24410485"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 [==============================] - 1s 1s/step - loss: 1.1492 - accuracy: 0.1667\n","Epoch 2/100\n","1/1 [==============================] - 0s 8ms/step - loss: 1.1400 - accuracy: 0.1667\n","Epoch 3/100\n","1/1 [==============================] - 0s 8ms/step - loss: 1.1317 - accuracy: 0.0000e+00\n","Epoch 4/100\n","1/1 [==============================] - 0s 8ms/step - loss: 1.1240 - accuracy: 0.0000e+00\n","Epoch 5/100\n","1/1 [==============================] - 0s 9ms/step - loss: 1.1170 - accuracy: 0.0000e+00\n","Epoch 6/100\n","1/1 [==============================] - 0s 8ms/step - loss: 1.1105 - accuracy: 0.1667\n","Epoch 7/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.1044 - accuracy: 0.1667\n","Epoch 8/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0985 - accuracy: 0.3333\n","Epoch 9/100\n","1/1 [==============================] - 0s 15ms/step - loss: 1.0929 - accuracy: 0.5000\n","Epoch 10/100\n","1/1 [==============================] - 0s 10ms/step - loss: 1.0874 - accuracy: 0.6667\n","Epoch 11/100\n","1/1 [==============================] - 0s 10ms/step - loss: 1.0820 - accuracy: 0.5000\n","Epoch 12/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0766 - accuracy: 0.5000\n","Epoch 13/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0712 - accuracy: 0.5000\n","Epoch 14/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0656 - accuracy: 0.5000\n","Epoch 15/100\n","1/1 [==============================] - 0s 9ms/step - loss: 1.0598 - accuracy: 0.5000\n","Epoch 16/100\n","1/1 [==============================] - 0s 15ms/step - loss: 1.0539 - accuracy: 0.5000\n","Epoch 17/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.0477 - accuracy: 0.5000\n","Epoch 18/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0412 - accuracy: 0.5000\n","Epoch 19/100\n","1/1 [==============================] - 0s 10ms/step - loss: 1.0344 - accuracy: 0.5000\n","Epoch 20/100\n","1/1 [==============================] - 0s 8ms/step - loss: 1.0272 - accuracy: 0.6667\n","Epoch 21/100\n","1/1 [==============================] - 0s 8ms/step - loss: 1.0196 - accuracy: 0.6667\n","Epoch 22/100\n","1/1 [==============================] - 0s 8ms/step - loss: 1.0116 - accuracy: 0.8333\n","Epoch 23/100\n","1/1 [==============================] - 0s 8ms/step - loss: 1.0032 - accuracy: 0.6667\n","Epoch 24/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.9943 - accuracy: 0.6667\n","Epoch 25/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.9849 - accuracy: 0.6667\n","Epoch 26/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.9751 - accuracy: 0.6667\n","Epoch 27/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.9647 - accuracy: 0.6667\n","Epoch 28/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.9538 - accuracy: 0.8333\n","Epoch 29/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.9425 - accuracy: 0.8333\n","Epoch 30/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.9306 - accuracy: 0.8333\n","Epoch 31/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.9182 - accuracy: 0.8333\n","Epoch 32/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.9052 - accuracy: 0.8333\n","Epoch 33/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.8918 - accuracy: 0.8333\n","Epoch 34/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.8780 - accuracy: 0.8333\n","Epoch 35/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.8636 - accuracy: 0.8333\n","Epoch 36/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.8489 - accuracy: 0.8333\n","Epoch 37/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.8338 - accuracy: 0.8333\n","Epoch 38/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.8183 - accuracy: 1.0000\n","Epoch 39/100\n","1/1 [==============================] - 0s 22ms/step - loss: 0.8025 - accuracy: 1.0000\n","Epoch 40/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.7865 - accuracy: 1.0000\n","Epoch 41/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.7702 - accuracy: 1.0000\n","Epoch 42/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.7538 - accuracy: 1.0000\n","Epoch 43/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.7372 - accuracy: 1.0000\n","Epoch 44/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.7206 - accuracy: 1.0000\n","Epoch 45/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.7040 - accuracy: 1.0000\n","Epoch 46/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6873 - accuracy: 1.0000\n","Epoch 47/100\n","1/1 [==============================] - 0s 7ms/step - loss: 0.6707 - accuracy: 1.0000\n","Epoch 48/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6542 - accuracy: 1.0000\n","Epoch 49/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6378 - accuracy: 1.0000\n","Epoch 50/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6215 - accuracy: 1.0000\n","Epoch 51/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6054 - accuracy: 1.0000\n","Epoch 52/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.5895 - accuracy: 1.0000\n","Epoch 53/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.5739 - accuracy: 1.0000\n","Epoch 54/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.5584 - accuracy: 1.0000\n","Epoch 55/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5433 - accuracy: 1.0000\n","Epoch 56/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5283 - accuracy: 1.0000\n","Epoch 57/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5137 - accuracy: 1.0000\n","Epoch 58/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4993 - accuracy: 1.0000\n","Epoch 59/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4853 - accuracy: 1.0000\n","Epoch 60/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4715 - accuracy: 1.0000\n","Epoch 61/100\n","1/1 [==============================] - 0s 22ms/step - loss: 0.4580 - accuracy: 1.0000\n","Epoch 62/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.4448 - accuracy: 1.0000\n","Epoch 63/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.4320 - accuracy: 1.0000\n","Epoch 64/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.4194 - accuracy: 1.0000\n","Epoch 65/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.4071 - accuracy: 1.0000\n","Epoch 66/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 1.0000\n","Epoch 67/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.3835 - accuracy: 1.0000\n","Epoch 68/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.3721 - accuracy: 1.0000\n","Epoch 69/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.3611 - accuracy: 1.0000\n","Epoch 70/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.3504 - accuracy: 1.0000\n","Epoch 71/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.3399 - accuracy: 1.0000\n","Epoch 72/100\n","1/1 [==============================] - 0s 7ms/step - loss: 0.3298 - accuracy: 1.0000\n","Epoch 73/100\n","1/1 [==============================] - 0s 7ms/step - loss: 0.3200 - accuracy: 1.0000\n","Epoch 74/100\n","1/1 [==============================] - 0s 7ms/step - loss: 0.3104 - accuracy: 1.0000\n","Epoch 75/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 1.0000\n","Epoch 76/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.2923 - accuracy: 1.0000\n","Epoch 77/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.2837 - accuracy: 1.0000\n","Epoch 78/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.2753 - accuracy: 1.0000\n","Epoch 79/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.2673 - accuracy: 1.0000\n","Epoch 80/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.2595 - accuracy: 1.0000\n","Epoch 81/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.2520 - accuracy: 1.0000\n","Epoch 82/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2448 - accuracy: 1.0000\n","Epoch 83/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2378 - accuracy: 1.0000\n","Epoch 84/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.2311 - accuracy: 1.0000\n","Epoch 85/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2247 - accuracy: 1.0000\n","Epoch 86/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2185 - accuracy: 1.0000\n","Epoch 87/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2125 - accuracy: 1.0000\n","Epoch 88/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2067 - accuracy: 1.0000\n","Epoch 89/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2011 - accuracy: 1.0000\n","Epoch 90/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.1958 - accuracy: 1.0000\n","Epoch 91/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.1906 - accuracy: 1.0000\n","Epoch 92/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.1857 - accuracy: 1.0000\n","Epoch 93/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.1809 - accuracy: 1.0000\n","Epoch 94/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.1763 - accuracy: 1.0000\n","Epoch 95/100\n","1/1 [==============================] - 0s 17ms/step - loss: 0.1718 - accuracy: 1.0000\n","Epoch 96/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.1675 - accuracy: 1.0000\n","Epoch 97/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.1634 - accuracy: 1.0000\n","Epoch 98/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.1594 - accuracy: 1.0000\n","Epoch 99/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.1556 - accuracy: 1.0000\n","Epoch 100/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.1519 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fcb1dbe1710>"]},"metadata":{},"execution_count":55}],"source":["gru_model.fit(train_X, train_Y, epochs= 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1662133901311,"user_tz":-540,"elapsed":473,"user":{"displayName":"이소연","userId":"16388319312927188329"}},"id":"JQQ6bRosysnD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3258a930-25ec-4d7e-fdd7-1cfbb765d116"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.8838949  0.03892433 0.07718088]\n"," [0.03276091 0.89175344 0.07548558]\n"," [0.12529185 0.05806499 0.8166431 ]]\n","[0 1 2]\n","\tPrediction str:  SVO\n","[[0.8183433  0.04454137 0.13711534]\n"," [0.03734664 0.8973856  0.06526773]\n"," [0.07024387 0.06087027 0.8688859 ]]\n","[0 1 2]\n","\tPrediction str:  SVO\n"]}],"source":["predictions = gru_model.predict(train_X)\n","for i, prediction in enumerate(predictions):\n","  print(prediction)\n","  print(np.argmax(prediction, axis=1))\n","  result_str = [idx2tag[c] for c in np.argmax(prediction, axis=1) ]\n","  print(\"\\tPrediction str: \", \"\".join(result_str))\n"]},{"cell_type":"markdown","metadata":{"id":"XHjLtdazysnD"},"source":["모델을 이해하려면 weight 개수(W0\\~Wn)를 세어봐야 합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1662133901311,"user_tz":-540,"elapsed":5,"user":{"displayName":"이소연","userId":"16388319312927188329"}},"id":"hR3ohllDysnD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4f56b064-d1e1-4486-83d6-9d1be22ccca2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," GRU-1 (GRU)                 (None, 3, 3)              72        \n","                                                                 \n"," hidden-to-output (Dense)    (None, 3, 3)              12        \n","                                                                 \n","=================================================================\n","Total params: 84\n","Trainable params: 84\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["gru_model.summary()"]},{"cell_type":"code","source":["for model_weight in gru_model.weights:\n","    print(model_weight.name, '=>', model_weight.shape)"],"metadata":{"id":"Uy0MKRyLysnD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 문제1"],"metadata":{"id":"I2rUh3ul5uyx"}},{"cell_type":"code","source":["model = Sequential()\n","model.add(GRU(9, input_dim = 10, return_sequences=True, reset_after=False))\n","# reset_after : keras 구현을 하면서 병렬처리를 위해 공식을 수정(bias를 2개로 나눔)하였는데, 원래 논문에 나온 공식으로 계산하기 위해 False로 수정\n","model.add(GRU(6, reset_after = False))\n","model.add(Dense(3))\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662134033334,"user_tz":-540,"elapsed":561,"user":{"displayName":"이소연","userId":"16388319312927188329"}},"outputId":"b055acee-0e27-43db-d418-74667f76ea1c","id":"JAykizT85uyx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," gru_6 (GRU)                 (None, None, 9)           540       \n","                                                                 \n"," gru_7 (GRU)                 (None, 6)                 288       \n","                                                                 \n"," dense_6 (Dense)             (None, 3)                 21        \n","                                                                 \n","=================================================================\n","Total params: 849\n","Trainable params: 849\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["- W_reset : (num_units + input_dim + 1) * num_units\n","- W_update : (num_units + input_dim + 1) * num_units\n","- W_new : (num_units + input_dim + 1) * num_units\n"],"metadata":{"id":"ukP2frBF_AJm"}},{"cell_type":"code","source":["# 첫번째 레이어의 파리미터 개수"],"metadata":{"id":"amdHJ3TD5uyy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 두번째 레이어의 파라미터 개수"],"metadata":{"id":"B8Vu4AYR5uyy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 세번째 레이어의 파리미터 개수"],"metadata":{"id":"qY-kw6jE5uyy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### reference"],"metadata":{"id":"p_IsqbYB8ZCr"}},{"cell_type":"markdown","source":["- https://github.com/ukairia777/tensorflow-nlp-tutorial/blob/main/08.%20RNN/8-4.%20understanding_simplernn_and_lstm.ipynb"],"metadata":{"id":"DREMZ3E18WdL"}}]}