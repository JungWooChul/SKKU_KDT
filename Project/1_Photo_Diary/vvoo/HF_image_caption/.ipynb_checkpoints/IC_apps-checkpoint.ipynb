{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 14:53:46.535909: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 14:53:47.552470: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-06-29 14:53:47.552614: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-06-29 14:53:47.552628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Some weights of the model checkpoint at nlpconnect/vit-gpt2-image-captioning were not used when initializing VisionEncoderDecoderModel: ['decoder.transformer.h.11.attn.bias', 'decoder.transformer.h.2.attn.masked_bias', 'decoder.transformer.h.7.attn.masked_bias', 'decoder.transformer.h.3.crossattention.masked_bias', 'decoder.transformer.h.4.attn.bias', 'decoder.transformer.h.7.crossattention.bias', 'decoder.transformer.h.11.attn.masked_bias', 'decoder.transformer.h.5.crossattention.bias', 'decoder.transformer.h.5.attn.bias', 'decoder.transformer.h.5.crossattention.masked_bias', 'decoder.transformer.h.11.crossattention.bias', 'decoder.transformer.h.7.crossattention.masked_bias', 'decoder.transformer.h.2.crossattention.masked_bias', 'decoder.transformer.h.10.crossattention.bias', 'decoder.transformer.h.0.crossattention.masked_bias', 'decoder.transformer.h.11.crossattention.masked_bias', 'decoder.transformer.h.4.attn.masked_bias', 'decoder.transformer.h.1.crossattention.masked_bias', 'decoder.transformer.h.10.attn.bias', 'decoder.transformer.h.4.crossattention.bias', 'decoder.transformer.h.9.attn.bias', 'decoder.transformer.h.2.crossattention.bias', 'decoder.transformer.h.3.attn.masked_bias', 'decoder.transformer.h.2.attn.bias', 'decoder.transformer.h.1.crossattention.bias', 'decoder.transformer.h.10.attn.masked_bias', 'decoder.transformer.h.8.attn.bias', 'decoder.transformer.h.6.attn.bias', 'decoder.transformer.h.6.crossattention.masked_bias', 'decoder.transformer.h.1.attn.bias', 'decoder.transformer.h.0.attn.masked_bias', 'decoder.transformer.h.8.attn.masked_bias', 'decoder.transformer.h.0.attn.bias', 'decoder.transformer.h.8.crossattention.masked_bias', 'decoder.transformer.h.9.crossattention.bias', 'decoder.transformer.h.10.crossattention.masked_bias', 'decoder.transformer.h.6.attn.masked_bias', 'decoder.transformer.h.8.crossattention.bias', 'decoder.transformer.h.9.crossattention.masked_bias', 'decoder.transformer.h.3.attn.bias', 'decoder.transformer.h.4.crossattention.masked_bias', 'decoder.transformer.h.6.crossattention.bias', 'decoder.transformer.h.7.attn.bias', 'decoder.transformer.h.0.crossattention.bias', 'decoder.transformer.h.1.attn.masked_bias', 'decoder.transformer.h.3.crossattention.bias', 'decoder.transformer.h.9.attn.masked_bias', 'decoder.transformer.h.5.attn.masked_bias']\n",
      "- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "max_length = 16\n",
    "num_beams = 4\n",
    "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_step(image_paths):\n",
    "  images = []\n",
    "  for image_path in image_paths:\n",
    "      i_image = Image.open(image_path)\n",
    "      if i_image.mode != \"RGB\":\n",
    "          i_image = i_image.convert(mode=\"RGB\")\n",
    "\n",
    "      images.append(i_image)\n",
    "      \n",
    "  pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
    "  pixel_values = pixel_values.to(device)\n",
    "\n",
    "  output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "\n",
    "  preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "  preds = [pred.strip() for pred in preds]\n",
    "  i_image.close()\n",
    "  return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 9395/118287 [49:59<8:44:31,  3.46it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 13%|█▎        | 14914/118287 [1:17:48<9:12:36,  3.12it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 20%|█▉        | 23508/118287 [2:00:04<7:18:12,  3.60it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 25%|██▍       | 29413/118287 [2:30:09<6:37:55,  3.72it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 34%|███▎      | 39775/118287 [3:21:26<6:35:55,  3.30it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 39%|███▊      | 45709/118287 [3:50:26<5:22:51,  3.75it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 44%|████▎     | 51704/118287 [4:19:55<5:41:03,  3.25it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 51%|█████     | 59889/118287 [5:00:13<6:52:20,  2.36it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 80%|███████▉  | 94092/118287 [7:52:56<1:54:33,  3.52it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 85%|████████▌ | 100619/118287 [8:26:22<1:26:52,  3.39it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 90%|█████████ | 106901/118287 [8:58:23<58:50,  3.23it/s]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 93%|█████████▎| 110388/118287 [9:15:59<40:04,  3.28it/s]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 118287/118287 [9:56:16<00:00,  3.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000044379...</td>\n",
       "      <td>[a bedroom with a bed and a dresser]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000032752...</td>\n",
       "      <td>[a black and white horse standing next to a cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000028883...</td>\n",
       "      <td>[a cut in half sandwich sitting on top of a cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000052356...</td>\n",
       "      <td>[two dogs sitting in the back of a pick up truck]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000004838...</td>\n",
       "      <td>[a white horse standing on top of a sandy beach]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118282</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000004162...</td>\n",
       "      <td>[a brown and white dog laying on the ground wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118283</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000057165...</td>\n",
       "      <td>[two women in a kitchen with a plate of food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118284</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000041587...</td>\n",
       "      <td>[a piece of cake sitting on top of a paper plate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118285</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000000883...</td>\n",
       "      <td>[a toilet sitting in the middle of a forest]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118286</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000000162...</td>\n",
       "      <td>[two people playing a video game in a living r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118287 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 img_path  \\\n",
       "0       /home/gi2570/coco/images/train2017/00000044379...   \n",
       "1       /home/gi2570/coco/images/train2017/00000032752...   \n",
       "2       /home/gi2570/coco/images/train2017/00000028883...   \n",
       "3       /home/gi2570/coco/images/train2017/00000052356...   \n",
       "4       /home/gi2570/coco/images/train2017/00000004838...   \n",
       "...                                                   ...   \n",
       "118282  /home/gi2570/coco/images/train2017/00000004162...   \n",
       "118283  /home/gi2570/coco/images/train2017/00000057165...   \n",
       "118284  /home/gi2570/coco/images/train2017/00000041587...   \n",
       "118285  /home/gi2570/coco/images/train2017/00000000883...   \n",
       "118286  /home/gi2570/coco/images/train2017/00000000162...   \n",
       "\n",
       "                                                   prompt  \n",
       "0                    [a bedroom with a bed and a dresser]  \n",
       "1       [a black and white horse standing next to a cr...  \n",
       "2       [a cut in half sandwich sitting on top of a cu...  \n",
       "3       [two dogs sitting in the back of a pick up truck]  \n",
       "4        [a white horse standing on top of a sandy beach]  \n",
       "...                                                   ...  \n",
       "118282  [a brown and white dog laying on the ground wi...  \n",
       "118283      [two women in a kitchen with a plate of food]  \n",
       "118284  [a piece of cake sitting on top of a paper plate]  \n",
       "118285       [a toilet sitting in the middle of a forest]  \n",
       "118286  [two people playing a video game in a living r...  \n",
       "\n",
       "[118287 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "img_to_text = {'img_path':[], 'prompt':[]}\n",
    "file_path = f'/home/gi2570/coco/images/train2017/'\n",
    "list_images= glob.glob(file_path + '*.jpg')\n",
    "\n",
    "img_to_text['img_path'].extend(list_images)\n",
    "for img in tqdm(list_images):\n",
    "    img_to_text['prompt'].append(predict_step([img]))\n",
    "pd.DataFrame(img_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000044379...</td>\n",
       "      <td>[a bedroom with a bed and a dresser]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000032752...</td>\n",
       "      <td>[a black and white horse standing next to a cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000028883...</td>\n",
       "      <td>[a cut in half sandwich sitting on top of a cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000052356...</td>\n",
       "      <td>[two dogs sitting in the back of a pick up truck]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000004838...</td>\n",
       "      <td>[a white horse standing on top of a sandy beach]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118282</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000004162...</td>\n",
       "      <td>[a brown and white dog laying on the ground wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118283</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000057165...</td>\n",
       "      <td>[two women in a kitchen with a plate of food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118284</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000041587...</td>\n",
       "      <td>[a piece of cake sitting on top of a paper plate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118285</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000000883...</td>\n",
       "      <td>[a toilet sitting in the middle of a forest]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118286</th>\n",
       "      <td>/home/gi2570/coco/images/train2017/00000000162...</td>\n",
       "      <td>[two people playing a video game in a living r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118287 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 img_path  \\\n",
       "0       /home/gi2570/coco/images/train2017/00000044379...   \n",
       "1       /home/gi2570/coco/images/train2017/00000032752...   \n",
       "2       /home/gi2570/coco/images/train2017/00000028883...   \n",
       "3       /home/gi2570/coco/images/train2017/00000052356...   \n",
       "4       /home/gi2570/coco/images/train2017/00000004838...   \n",
       "...                                                   ...   \n",
       "118282  /home/gi2570/coco/images/train2017/00000004162...   \n",
       "118283  /home/gi2570/coco/images/train2017/00000057165...   \n",
       "118284  /home/gi2570/coco/images/train2017/00000041587...   \n",
       "118285  /home/gi2570/coco/images/train2017/00000000883...   \n",
       "118286  /home/gi2570/coco/images/train2017/00000000162...   \n",
       "\n",
       "                                                   prompt  \n",
       "0                    [a bedroom with a bed and a dresser]  \n",
       "1       [a black and white horse standing next to a cr...  \n",
       "2       [a cut in half sandwich sitting on top of a cu...  \n",
       "3       [two dogs sitting in the back of a pick up truck]  \n",
       "4        [a white horse standing on top of a sandy beach]  \n",
       "...                                                   ...  \n",
       "118282  [a brown and white dog laying on the ground wi...  \n",
       "118283      [two women in a kitchen with a plate of food]  \n",
       "118284  [a piece of cake sitting on top of a paper plate]  \n",
       "118285       [a toilet sitting in the middle of a forest]  \n",
       "118286  [two people playing a video game in a living r...  \n",
       "\n",
       "[118287 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(img_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tmp = pd.DataFrame(img_to_text)\n",
    "df_tmp.to_csv(\"/home/gi2570/coco/img_caption/train2017_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_10672/334474735.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimg_to_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mimg_to_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prompt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdf_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_to_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/tmp/ipykernel_10672/1633623755.py\u001b[0m in \u001b[0;36mpredict_step\u001b[0;34m(image_paths)\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mi_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mi_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "coco_lst = ['test', 'unlabeled', 'val']\n",
    "for i in coco_lst:\n",
    "    img_to_text = {'img_path':[], 'prompt':[]}\n",
    "    file_path = f'/home/gi2570/coco/images/{i}2017/'\n",
    "    list_images= glob.glob(file_path + '*.jpg')\n",
    "\n",
    "    img_to_text['img_path'].extend(list_images)\n",
    "    for img in tqdm(list_images):\n",
    "        img_to_text['prompt'].append(predict_step([img]))\n",
    "        \n",
    "    df_tmp = pd.DataFrame(img_to_text)\n",
    "    df_tmp.to_csv(f\"/home/gi2570/coco/img_caption/{i}2017_df.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd1d485664b51f0592ac0f5de8ec7c658d25bf980dade393a2332f18e9f31231"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
